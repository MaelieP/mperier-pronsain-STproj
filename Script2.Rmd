---
title: "Script2"
author: "Maëlie Perier"
date: "2024-05-18"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## On charge les packages

```{r}
install.packages('tinytex')
tinytex::install_tinytex()
library(urca)
#library(fUnitRoots)
library(zoo)
library(lubridate)
#install.packages("tseries")
#install.packages("forecast")
library(forecast)
library(tseries)
library(stargazer)
#library(astsa)
library(ellipse)
library(ggplot2)

```

## On importe les données - gaz naturel 
Ensuite on prend les données de 2000 à 2019 pour éviter les chocs causés par les chocs pétroliers de 1990 ainsi que le Covid-19. 
On range le df par date puis on le converti en série temporelle

```{r}
datafile <- "~/Desktop/valeurs_mensuelles.csv"
data <- read.csv(datafile, sep = ";", skip = 3, col.names = c("Date", "x1", "ignore"))

data$Date <- as.yearmon(data$Date)
data_filt <- subset(data, Date >= as.yearmon("Jan 2000") & Date <= as.yearmon("Dec 2019"))
data_filt <- data_filt[order(data_filt$Date), ]
data_ts_ <- ts(data_filt$x1, start = data_filt$Date[1], frequency = 12)

data_ts_entiere <- ts(data$x1, start = data$Date[1], frequency = 12)

data_ts <- zoo(data_ts_, order.by = index(data_ts_))
```

## Including Plots


```{r}
plot(data_ts, xlab="Years", ylab = "Industrial Production Index")
acf(data_ts, 20*12, ylim=c(-0.5, 1))
pacf(data_ts, 6*12, ylim=c(-0.4, 0.5))
```

```{r}
data_ts_diff <- diff(data_ts)
plot(data_ts_diff, xlab="Years", ylab = "Industrial Production Index differencié")

acf(data_ts_diff, 10*12) 
pacf(data_ts_diff, 10*12)

qmax <- 7
pmax <- 2

```
La série semble stationnaire, la moyenne semble nulle même si la variance évolue entre avant et après 2013. Nous souhaitons désormais vérifier notre hypothèse de stationarité à l'aide de qqs tests. 

```{r}
adf_test_result <- adf.test(data_ts_diff)
print(adf_test_result)

pp_result <- pp.test(data_ts_diff)
print(pp_result)

kpss_result <- kpss.test(data_ts_diff)
print(kpss_result)
```
Les tests confirment qu'on rejete l'hypothèse de stationarité à tous les seuils
En regardant les graphiques précédents, il semble qu'on ait pmax = 2 et qmax = 7 

On regarde si le modèle ARIMA(2,0,7) est bien ajusté et valide (respectivement que ses coeffs sont significatifs et que ces résidus ne sont pas autocorrélés)

```{r}
arima207 <- arima(data_ts_diff,c(2,0,7))

signif <- function(estim){
coef <- estim$coef
se <- sqrt(diag(estim$var.coef))
t <- coef/se
pval <- ((1-pnorm(abs(t)))*2)
return(rbind(coef,se,pval))
}
signif(arima207)

Box.test(arima207$residuals,lag=15, type="Ljung-Box", fitdf=6)

Qtests <- function(series, k, fitdf=0) {
pvals <- apply(matrix(1:k), 1, FUN=function(l) {
pval <- if (l<=fitdf) NA else Box.test(series, lag=l, type="Ljung-Box", fitdf=fitdf)$p.value 
return(c("lag"=l,"pval"=pval))
})
return(t(pvals))
}
Qtests(arima207$residuals, 15, 6)

```
L'absence d'autocorrélation entre les résidus n'est jamais rejetée à 95% jusqu'à 15 retards. Le modèle semble donc valide. Toutefois, il n'est pas bien ajusté car les coefficients MA(q) avec q > 4 ne sont pas significatifs. 
On fait une fonction pour tester tous les modèles ARIMA(p,d,q) avec p < pmax et q < qmax et voir s'ils sont 1) bien ajustés et 2) valides. Une fois cela fait, on choisira entre les différents modèles selectionnés. 


```{r}
signif <- function(estim){# test des significations individuelles des coefficients 
coef <- estim$coef
se <- sqrt(diag(estim$var.coef))
t <- coef/se
pval <- (1-pnorm(abs(t)))*2
return(rbind(coef,pval)) 
}
for (p in 0:2) { 
  for (q in 0:7) {
    print(c(p,q))
    print(signif(arima(data_ts, c(p,0,q), include.mean = FALSE))) }
}
```
On retient les modèles ARIMA suivant qui sont ajustés : 
*ARIMA(0,0,1)
*ARIMA(0,0,2)
*ARIMA(0,0,3)
*ARIMA(0,0,4)
*ARIMA(0,0,5)
*ARIMA(0,0,6)
*ARIMA(0,0,7)
*ARIMA(1,0,0)
*ARIMA(1,0,2)
*ARIMA(2,0,1)
```{r}
arima_coefs <- list(
  c(0, 0, 1), c(0, 0, 2), c(0, 0, 3),
  c(0, 0, 4), c(0, 0, 5), c(0, 0, 6),
  c(0, 0, 7), c(1, 0, 0), c(1, 0, 2),
  c(2, 0, 1)
)

# Loop through the list of coefficients
valid_arima <- list()
for (coefs in arima_coefs) {
  cat("\nFitting ARIMA(", coefs[1], ",", coefs[2], ",", coefs[3], ") model:\n", sep = "")
  tryCatch({
    model <- arima(data_ts, order = coefs, include.mean = FALSE)
    residuals <- residuals(model)
    
    # Perform Box-Ljung test on residuals
    box_test <- Box.test(residuals, lag = 15, type = "Ljung-Box", fitdf = sum(coefs))
    cat("\nBox-Ljung Test:\n")
    print(box_test)
    
    if (box_test$p.value > 0.05) {
      valid_arima <- c(valid_arima, list(coefs))
    }
    
  })
}

cat("\nList of ARIMA models with Box-Ljung test p-value > 0.05:\n")
for (model in valid_arima) {
  cat("ARIMA(", model[[1]], ",", model[[2]], ",", model[[3]], ")\n", sep = "")
}
```
Il nous reste donc plus que deux modèles qui sont à la fois valides et avec des coefficients significatifs : ARIMA(1,0,2) et ARIMA(2,0,1)
Arbitrons entre les deux à l'aide des AIC/BIC

```{r}
aic_12 <- AIC(arima(data_ts, order=c(1,0,2)))
bic_12 <- BIC(arima(data_ts, order=c(1,0,2)))
aic_21 <- AIC(arima(data_ts, order=c(2,0,1)))
bic_21 <- BIC(arima(data_ts, order=c(2,0,1)))

cat("AIC et BIC de l'ARMA(1,2)", aic_12, "/", bic_12,"\nAIC et BIC de l'ARMA(2,1)", aic_21, "/", bic_21)

```
Les AIC et BIC de l'ARMA(1,2) sont légèrement plus faibles, on opte donc pour ce modèle là. 


### Question 5
Puisque notre série différenciée suit un ARMA(1,2), notre série initiale suit donc un ARIMA(1,1,2) 

We can conclude that the initial series $Z_t$ follows an ARMA(1,2) with drift.
Let us first write the expression of the differentiated series, which follows an ARMA(1,2):

$$
\Delta Z_t =: X_t = \phi_1 X_{t-1} + \epsilon_t + \psi_1 \epsilon_{t-1} + \psi_2 \epsilon_{t-2}
$$

hence

$$
(1 - \phi_1 B)X_t = (1 + \psi_1 B + \psi_2 B^2) \epsilon_t
$$

which gives

$$
(1 - \phi_1 B)(1 - B)Z_t = (1 + \psi_1 B + \psi_2 B^2) \epsilon_t
$$

Replacing the $\phi_1, \psi_1, \psi_2$ by the estimated coefficients (that we obtained earlier), we get

$$
\[
(1 - 0.999 B) Z_t = (1 - 0.212 B - 0.346 B^2) \epsilon_t
\]
$$

or

$$
\[
Z_t = 0.999 Z_{t-1} + \epsilon_t - 0.212 \epsilon_{t-1} - 0.346 \epsilon_{t-2}
\]
$$

```{r}
## Question 7: Diagnostic du modèle et vérification de l'hypothèse de normalité des résidus

# Ajustement du modèle ARIMA(1,0,2)
fit <- arima(data_ts, order=c(1,0,2))

# Diagnostic du modèle ARIMA(1,0,2)
tsdiag(fit)

# Test de Jarque-Bera pour la normalité des résidus
jarque.bera.test(fit$residuals)

# Q-Q plot des résidus
qqnorm(fit$residuals)
qqline(fit$residuals, col = "red")

# Densité des résidus
plot(density(fit$residuals), lwd=0.5, xlim=range(fit$residuals), main="Densité des résidus")
mu <- mean(fit$residuals)
sigma <- sd(fit$residuals)
x <- seq(min(fit$residuals), max(fit$residuals), length.out=100)
y <- dnorm(x, mean=mu, sd=sigma)
lines(x, y, lwd=0.5, col="blue")


```
```{r}
## Question 8: Vérification des racines du modèle

# Extraction des coefficients du modèle ARIMA(1,0,2)
phi_1 <- as.numeric(fit$coef[1])
theta_1 <- as.numeric(fit$coef["ma1"])
theta_2 <- as.numeric(fit$coef["ma2"])
sigma2 <- as.numeric(fit$sigma2)

# Affichage des coefficients
phi_1
theta_1
theta_2
sigma2

# Vérification des racines
ar_coefs <- c(phi_1)
ma_coefs <- c(theta_1, theta_2)

# Vérification si les racines sont en dehors du cercle unité
ar_roots <- polyroot(c(1, -ar_coefs))
ma_roots <- polyroot(c(1, ma_coefs))

abs(ar_roots)
abs(ma_roots)

all(abs(ar_roots) > 1)
all(abs(ma_roots) > 1)

## Prédiction

# Prédiction des deux prochaines valeurs
XT1 <- predict(fit, n.ahead=2)$pred[1]
XT2 <- predict(fit, n.ahead=2)$pred[2]

XT1
XT2

# Prédiction pour la série
fore <- forecast(fit, h=5, level=95)
par(mfrow=c(1,1))
plot(fore, xlim=c(2018,2024), col=1, fcol=2, shaded=TRUE, xlab="Temps", ylab="Valeur", main="Prévision pour la série")

# Calcul de la matrice de variance-covariance
Sigma <- matrix(c(sigma2, theta_1 * sigma2, theta_2 * sigma2,
                  theta_1 * sigma2, sigma2, 0,
                  theta_2 * sigma2, 0, sigma2), ncol=3)

# Plot de la région de confiance bivariée à 95%
library(ellipse)
plot(XT1, XT2, xlim=c(-10, 10), ylim=c(-10, 10), xlab="Prévision pour X_{T+1}", ylab="Prévision pour X_{T+2}",
     main="Région de confiance bivariée à 95%")
ellipse(Sigma[1:2, 1:2], center=c(XT1, XT2), type="l", col="red", radius=1)
points(XT1, XT2, col="blue")
abline(h=XT2, v=XT1, col="blue")
abline(h=0, v=0)
```

